# /// script
# dependencies = []
#
# [tool.griptape-nodes]
# name = "qwen_edit_2509_camera_control"
# schema_version = "0.13.0"
# engine_version_created_with = "0.64.0"
# node_libraries_referenced = [["Griptape Nodes Advanced Media Library", "0.60.0"]]
# node_types_used = [["Griptape Nodes Advanced Media Library", "DiffusionPipelineBuilderNode"], ["Griptape Nodes Advanced Media Library", "DiffusionPipelineRuntimeNode"], ["Griptape Nodes Advanced Media Library", "LoadLora"]]
# description = "Control camera angles and perspective with Qwen-Image-Edit-2509"
# image = "https://raw.githubusercontent.com/griptape-ai/griptape-nodes/refs/heads/main/libraries/griptape_nodes_advanced_media_library/workflows/templates/thumbnail_qwen.webp"
# is_griptape_provided = true
# is_template = true
# creation_date = 2025-11-19T11:55:49.964965Z
# last_modified_date = 2025-11-19T14:24:42.207550Z
#
# ///

import pickle
from griptape.artifacts.image_url_artifact import ImageUrlArtifact
from griptape_nodes.node_library.library_registry import IconVariant, NodeDeprecationMetadata, NodeMetadata
from griptape_nodes.retained_mode.events.connection_events import CreateConnectionRequest
from griptape_nodes.retained_mode.events.flow_events import CreateFlowRequest
from griptape_nodes.retained_mode.events.library_events import LoadLibrariesRequest
from griptape_nodes.retained_mode.events.node_events import CreateNodeGroupRequest, CreateNodeRequest
from griptape_nodes.retained_mode.events.parameter_events import AddParameterToNodeRequest, AlterParameterDetailsRequest, SetParameterValueRequest
from griptape_nodes.retained_mode.griptape_nodes import GriptapeNodes

GriptapeNodes.handle_request(LoadLibrariesRequest())

context_manager = GriptapeNodes.ContextManager()

if not context_manager.has_current_workflow():
    context_manager.push_workflow(workflow_name='qwen_edit_2509_camera_control')

"""
1. We've collated all of the unique parameter values into a dictionary so that we do not have to duplicate them.
   This minimizes the size of the code, especially for large objects like serialized image files.
2. We're using a prefix so that it's clear which Flow these values are associated with.
3. The values are serialized using pickle, which is a binary format. This makes them harder to read, but makes
   them consistently save and load. It allows us to serialize complex objects like custom classes, which otherwise
   would be difficult to serialize.
"""
top_level_unique_values_dict = {'6ed0d013-6611-499f-b6e3-58f072e7c5b9': pickle.loads(b'\x80\x04\x95\\\x00\x00\x00\x00\x00\x00\x00\x8cXQwenImageEditPipeline-c18b833e0d32a45476161dfae5354fa4cf757a08c5aac454b9158374a3c9ac0f-0\x94.'), '67f73190-9d8f-48a9-b621-89959bc6cfff': pickle.loads(b'\x80\x04\x95\x08\x00\x00\x00\x00\x00\x00\x00\x8c\x04Qwen\x94.'), '667b485d-c1da-4e48-89a1-553d3a747c57': pickle.loads(b'\x80\x04\x95\x19\x00\x00\x00\x00\x00\x00\x00\x8c\x15QwenImageEditPipeline\x94.'), 'a1254142-7476-4a5c-8e0a-416d47aa44b9': pickle.loads(b'\x80\x04\x95\x1d\x00\x00\x00\x00\x00\x00\x00\x8c\x19Qwen/Qwen-Image-Edit-2509\x94.'), '966f1035-8051-4146-8dd8-85b1b9d1df37': pickle.loads(b'\x80\x04\x95\x1f\x00\x00\x00\x00\x00\x00\x00\x8c\x1bQwen/Qwen2.5-VL-7B-Instruct\x94.'), '381e4c4b-b524-46c1-bbeb-4bfc7511c73d': pickle.loads(b'\x80\x04\x95#\x00\x00\x00\x00\x00\x00\x00\x8c\x1fFlowMatchEulerDiscreteScheduler\x94.'), '15bb28e9-4c84-472c-a2d9-17e64ba4d683': pickle.loads(b'\x80\x04\x956\x01\x00\x00\x00\x00\x00\x00}\x94(\x8c\x12base_image_seq_len\x94M\x00\x01\x8c\nbase_shift\x94G?\xf1\x93\xeaz\xad\x03\x0b\x8c\rinvert_sigmas\x94\x89\x8c\x11max_image_seq_len\x94M\x00 \x8c\tmax_shift\x94G?\xf1\x93\xeaz\xad\x03\x0b\x8c\x13num_train_timesteps\x94M\xe8\x03\x8c\x05shift\x94K\x01\x8c\x0eshift_terminal\x94N\x8c\x13stochastic_sampling\x94\x89\x8c\x0ftime_shift_type\x94\x8c\x0bexponential\x94\x8c\x0fuse_beta_sigmas\x94\x89\x8c\x14use_dynamic_shifting\x94\x88\x8c\x16use_exponential_sigmas\x94\x89\x8c\x11use_karras_sigmas\x94\x89u.'), 'bd222443-ac5d-46c8-8973-3f45152ca58f': pickle.loads(b'\x80\x04\x95\r\x00\x00\x00\x00\x00\x00\x00\x8c\tAutomatic\x94.'), 'a9ed14cc-8383-4c27-9f75-f42354d5b301': pickle.loads(b'\x80\x04\x89.'), 'b720d61a-4118-4078-985c-11cd7bdd8672': pickle.loads(b'\x80\x04\x95\x08\x00\x00\x00\x00\x00\x00\x00\x8c\x04None\x94.'), 'c92697b1-f932-47e9-8e49-bf6ad16a1f8c': pickle.loads(b'\x80\x04\x95O\x01\x00\x00\x00\x00\x00\x00]\x94(}\x94\x8c\x91C:\\Users\\dev\\.cache\\huggingface\\hub\\models--lightx2v--Qwen-Image-Lightning\\blobs\\2a32ce938ec71db2b49a817b4844ae86995569518dea56ee0ddc209cbe8e1377\x94G?\xf0\x00\x00\x00\x00\x00\x00s}\x94\x8c\x99C:\\Users\\dev\\.cache\\huggingface\\hub\\models--dx8152--Qwen-Edit-2509-Multiple-angles\\blobs\\e0cea9508025a39e41f50da0e7d10fbd9db182d057c745136a42ef8829914c8f\x94G?\xf0\x00\x00\x00\x00\x00\x00s]\x94e.'), '491f28f3-382c-4153-b570-cde4c0f553e5': pickle.loads(b'\x80\x04\x95\xa1\x00\x00\x00\x00\x00\x00\x00}\x94\x8c\x91C:\\Users\\dev\\.cache\\huggingface\\hub\\models--lightx2v--Qwen-Image-Lightning\\blobs\\2a32ce938ec71db2b49a817b4844ae86995569518dea56ee0ddc209cbe8e1377\x94G?\xf0\x00\x00\x00\x00\x00\x00s.'), '71564d82-c339-408d-be19-3c4e87cc80d9': pickle.loads(b'\x80\x04\x95\xa9\x00\x00\x00\x00\x00\x00\x00}\x94\x8c\x99C:\\Users\\dev\\.cache\\huggingface\\hub\\models--dx8152--Qwen-Edit-2509-Multiple-angles\\blobs\\e0cea9508025a39e41f50da0e7d10fbd9db182d057c745136a42ef8829914c8f\x94G?\xf0\x00\x00\x00\x00\x00\x00s.'), '5d1778a1-9003-412a-b0e2-49743433af41': pickle.loads(b'\x80\x04\x95\xeb\x0b\x00\x00\x00\x00\x00\x00X\xe4\x0b\x00\x00Pipeline configuration hash: QwenImagePipeline-c8f968123a4e3852fd131dc0b04a67d98bfbfce905079b6a6454e41e57a7bdf3-0\nPipeline configuration hash: QwenImagePipeline-c8f968123a4e3852fd131dc0b04a67d98bfbfce905079b6a6454e41e57a7bdf3-0\nPipeline configuration hash: QwenImagePipeline-c8f968123a4e3852fd131dc0b04a67d98bfbfce905079b6a6454e41e57a7bdf3-0\nPipeline configuration hash: QwenImagePipeline-c8f968123a4e3852fd131dc0b04a67d98bfbfce905079b6a6454e41e57a7bdf3-0\nPipeline configuration hash: QwenImagePipeline-c8f968123a4e3852fd131dc0b04a67d98bfbfce905079b6a6454e41e57a7bdf3-0\nPipeline configuration hash: QwenImagePipeline-c8f968123a4e3852fd131dc0b04a67d98bfbfce905079b6a6454e41e57a7bdf3-0\nPipeline configuration hash: QwenImageEditPipeline-bde485d86f02f5b410519d6d8e3d83e8749cb6713d45e19d5da1cd6d5f47d8a7-0\nPipeline configuration hash: QwenImageEditPipeline-de43c6585ad6eb6a276afdeb0625a1e9456756603393c2178fdf1020286e6a72-0\nPipeline configuration hash: QwenImageEditPipeline-de43c6585ad6eb6a276afdeb0625a1e9456756603393c2178fdf1020286e6a72-0\nPipeline configuration hash: QwenImageEditPipeline-de43c6585ad6eb6a276afdeb0625a1e9456756603393c2178fdf1020286e6a72-0\nPipeline configuration hash: QwenImageEditPipeline-64d0f227140f19d13df1437a7c7338596896767f69e29b94926db7717fd1078a-0\nPipeline configuration hash: QwenImageEditPipeline-4a5a041588acefc73ca5841374f480d28a570a7e5f744891b9005476f45b5fad-0\nPipeline configuration hash: QwenImageEditPipeline-4a5a041588acefc73ca5841374f480d28a570a7e5f744891b9005476f45b5fad-0\nPipeline configuration hash: QwenImageEditPipeline-4a5a041588acefc73ca5841374f480d28a570a7e5f744891b9005476f45b5fad-0\nPipeline configuration hash: QwenImageEditPipeline-4a5a041588acefc73ca5841374f480d28a570a7e5f744891b9005476f45b5fad-0\nPipeline configuration hash: QwenImageEditPipeline-4a5a041588acefc73ca5841374f480d28a570a7e5f744891b9005476f45b5fad-0\nPipeline configuration hash: QwenImageEditPipeline-4a5a041588acefc73ca5841374f480d28a570a7e5f744891b9005476f45b5fad-0\nPipeline configuration hash: QwenImageEditPipeline-4a5a041588acefc73ca5841374f480d28a570a7e5f744891b9005476f45b5fad-0\nPipeline configuration hash: QwenImageEditPipeline-9d048eb412031a635cdeff6ae7155844049932556b63d3e364a1b92ad9223641-0\nPipeline configuration hash: QwenImageEditPipeline-9d048eb412031a635cdeff6ae7155844049932556b63d3e364a1b92ad9223641-0\nPipeline configuration hash: QwenImageEditPipeline-c18b833e0d32a45476161dfae5354fa4cf757a08c5aac454b9158374a3c9ac0f-0\nPipeline configuration hash: QwenImageEditPipeline-c18b833e0d32a45476161dfae5354fa4cf757a08c5aac454b9158374a3c9ac0f-0\nPipeline configuration hash: QwenImageEditPipeline-c18b833e0d32a45476161dfae5354fa4cf757a08c5aac454b9158374a3c9ac0f-0\nPipeline configuration hash: QwenImageEditPipeline-c18b833e0d32a45476161dfae5354fa4cf757a08c5aac454b9158374a3c9ac0f-0\nPipeline configuration hash: QwenImageEditPipeline-c18b833e0d32a45476161dfae5354fa4cf757a08c5aac454b9158374a3c9ac0f-0\nPipeline configuration hash: QwenImageEditPipeline-c18b833e0d32a45476161dfae5354fa4cf757a08c5aac454b9158374a3c9ac0f-0\n\x94.'), '53d6fb00-893b-47e9-98af-a0240ef6a84b': pickle.loads(b'\x80\x04\x95\x04\x00\x00\x00\x00\x00\x00\x00\x8c\x00\x94.'), '06438398-4e7c-47e6-ae57-29d186ea5d9e': pickle.loads(b'\x80\x04\x95\n\x00\x00\x00\x00\x00\x00\x00G?\xf0\x00\x00\x00\x00\x00\x00.'), '81b9fe63-2831-4fbd-bd9d-64f5a46de29d': pickle.loads(b'\x80\x04\x95\xb0\x07\x00\x00\x00\x00\x00\x00X\xa9\x07\x00\x00# Workflow README\n\n## Overview\n\nThis workflow provides an example of how to change camera angles and perspectives of existing images while maintaining consistency.\n\nIt accomplishes this using [Qwen/Qwen-Image-Edit-2509](https://huggingface.co/Qwen/Qwen-Image-Edit-2509) with two key loras.\n- [lightx2v/Qwen-Image-Lightning](https://huggingface.co/lightx2v/Qwen-Image-Lightning) for faster images generation (4 steps instead of 50 steps).\n- [Qwen-Edit-2509-Multiple-angles LoRA model](https://huggingface.co/dx8152/Qwen-Edit-2509-Multiple-angles) for camera control.\n\nHere\'s is a brief explanation of what is going on in this workflow, working through the nodes left to right.\n\n1. The LoRAs are loaded.\n2. The diffusion pipeline is loaded into memory and configured. This step is slow, but cached for a session.\n3. Iterate over a list of prompts, generate an image for each, and collect the results into another list.\n4. Arrange the generated into a grid for easy viewing.\n\n## Instructions\n\n1. Download the models. (Click each link, then download, then close dialog.)\n   - [Qwen/Qwen-Image-Edit-2509](#model-management?search=Qwen/Qwen-Image-Edit-2509)\n   - [Qwen/Qwen2.5-VL-7B-Instruct](#model-management?search=Qwen/Qwen2.5-VL-7B-Instruct)\n   - [lightx2v/Qwen-Image-Lightning](#model-management?search=lightx2v/Qwen-Image-Lightning)\n   - [dx8152/Qwen-Edit-2509-Multiple-angles](#model-management?search=dx8152/Qwen-Edit-2509-Multiple-angles)\n1. Configure each LoRA following the instructions to the left of the "Load LoRA" nodes.\n1. Run the workflow.\n\n\n\n> ## Warning!\n> \n> Running diffusion models locally requires a decent amount of disk space, RAM and ideally a decent GPU. Lacking one of these may either result in this workflow not working for you or it running very very slowly, which is not a very fun experience after having waited a long time for the models to download. If you are unsure if you have the right requirements, then you probably don\'t.\n\n\n\x94.'), '12d18190-a9df-4253-9aaf-98661bcdd753': pickle.loads(b'\x80\x04K\x00.'), '3e2095c3-9066-4a38-a9f5-8f1506b7b84b': pickle.loads(b'\x80\x04\x95\x1b\x00\x00\x00\x00\x00\x00\x00\x8c\x17Rotate camera 45\xc2\xb0 left\x94.'), '16e7f5cc-756a-4782-92f0-046ad6396543': pickle.loads(b'\x80\x04\x95\xf9\x00\x00\x00\x00\x00\x00\x00]\x94(\x8c\x17Rotate camera 45\xc2\xb0 left\x94\x8c\x18Rotate camera 45\xc2\xb0 right\x94\x8c\x17Rotate camera 90\xc2\xb0 left\x94\x8c\x18Rotate camera 90\xc2\xb0 right\x94\x8c\x17Switch to top-down view\x94\x8c\x18Switch to low-angle view\x94\x8c\x17Switch to close-up lens\x94\x8c\x1eSwitch to medium close-up lens\x94\x8c\x17Switch to zoom out lens\x94e.'), '698c3c68-305c-4ea9-9ec8-6336c3d26233': pickle.loads(b'\x80\x04\x95~\x01\x00\x00\x00\x00\x00\x00\x8c%griptape.artifacts.image_url_artifact\x94\x8c\x10ImageUrlArtifact\x94\x93\x94)\x81\x94}\x94(\x8c\x04type\x94\x8c\x10ImageUrlArtifact\x94\x8c\x0bmodule_name\x94\x8c%griptape.artifacts.image_url_artifact\x94\x8c\x02id\x94\x8c d0e38d88b58f4deba679ef7927915927\x94\x8c\treference\x94N\x8c\x04meta\x94}\x94\x8c\x04name\x94h\n\x8c\x16encoding_error_handler\x94\x8c\x06strict\x94\x8c\x08encoding\x94\x8c\x05utf-8\x94\x8c\x05value\x94\x8cahttp://localhost:8125/workspace/staticfiles/8a2f8819-4017-414d-855f-c1c6e7d63c56.png?t=1763638169\x94ub.'), 'e4d82818-445a-436f-a6c0-b54d01cdb408': pickle.loads(b'\x80\x04]\x94.'), 'dfde1840-9b09-4715-864e-8035334312f9': pickle.loads(b'\x80\x04\x95\x02\x07\x00\x00\x00\x00\x00\x00]\x94(\x8c%griptape.artifacts.image_url_artifact\x94\x8c\x10ImageUrlArtifact\x94\x93\x94)\x81\x94}\x94(\x8c\x04type\x94\x8c\x10ImageUrlArtifact\x94\x8c\x0bmodule_name\x94\x8c%griptape.artifacts.image_url_artifact\x94\x8c\x02id\x94\x8c b74dd2dd76fd492787a66802af31e644\x94\x8c\treference\x94N\x8c\x04meta\x94}\x94\x8c\x04name\x94h\x0b\x8c\x16encoding_error_handler\x94\x8c\x06strict\x94\x8c\x08encoding\x94\x8c\x05utf-8\x94\x8c\x05value\x94\x8cahttp://localhost:8125/workspace/staticfiles/e105dcdf-76b2-4355-8fb5-b1587bd58d09.png?t=1763638132\x94ubh\x03)\x81\x94}\x94(h\x06h\x07h\x08h\th\n\x8c dec908c45b864dcbb36352c83e913986\x94h\x0cNh\r}\x94h\x0fh\x18h\x10h\x11h\x12h\x13h\x14\x8cahttp://localhost:8125/workspace/staticfiles/53082900-5fad-4c8c-8f17-3e9cb299f718.png?t=1763638137\x94ubh\x03)\x81\x94}\x94(h\x06h\x07h\x08h\th\n\x8c 09f7474a6a0d47f59b2c86df9442466f\x94h\x0cNh\r}\x94h\x0fh\x1dh\x10h\x11h\x12h\x13h\x14\x8cahttp://localhost:8125/workspace/staticfiles/c4b4afb4-46a9-4e55-924e-c172f0811d0c.png?t=1763638142\x94ubh\x03)\x81\x94}\x94(h\x06h\x07h\x08h\th\n\x8c 5339210ec6614c2aa53c669e7fcde186\x94h\x0cNh\r}\x94h\x0fh"h\x10h\x11h\x12h\x13h\x14\x8cahttp://localhost:8125/workspace/staticfiles/25714116-e6d6-4ff8-bdda-e5de9444631a.png?t=1763638146\x94ubh\x03)\x81\x94}\x94(h\x06h\x07h\x08h\th\n\x8c 9c05ed6ebbe040f6ac2c2bb34f14671b\x94h\x0cNh\r}\x94h\x0fh\'h\x10h\x11h\x12h\x13h\x14\x8cahttp://localhost:8125/workspace/staticfiles/db598343-f89e-4644-9892-a9c1c6ab98a4.png?t=1763638151\x94ubh\x03)\x81\x94}\x94(h\x06h\x07h\x08h\th\n\x8c fa224f3206f24c0baaf4e5b5a918a526\x94h\x0cNh\r}\x94h\x0fh,h\x10h\x11h\x12h\x13h\x14\x8cahttp://localhost:8125/workspace/staticfiles/16da1a63-c758-4492-b565-26853f7478b6.png?t=1763638155\x94ubh\x03)\x81\x94}\x94(h\x06h\x07h\x08h\th\n\x8c 26a43073f8c64307a961783f397d88a8\x94h\x0cNh\r}\x94h\x0fh1h\x10h\x11h\x12h\x13h\x14\x8cahttp://localhost:8125/workspace/staticfiles/0241cf2c-9c85-4094-819c-34bd8573b889.png?t=1763638160\x94ubh\x03)\x81\x94}\x94(h\x06h\x07h\x08h\th\n\x8c 257e864ff1414e1d840a8e10db7bf1b0\x94h\x0cNh\r}\x94h\x0fh6h\x10h\x11h\x12h\x13h\x14\x8cahttp://localhost:8125/workspace/staticfiles/8a38ce92-5cda-42db-ae88-73af5a6a418b.png?t=1763638165\x94ubh\x03)\x81\x94}\x94(h\x06h\x07h\x08h\th\n\x8c d0e38d88b58f4deba679ef7927915927\x94h\x0cNh\r}\x94h\x0fh;h\x10h\x11h\x12h\x13h\x14\x8cahttp://localhost:8125/workspace/staticfiles/8a2f8819-4017-414d-855f-c1c6e7d63c56.png?t=1763638169\x94ube.'), '97e10f91-14e1-489b-a2ff-f2225b9de101': pickle.loads(b'\x80\x04\x95\x0b\x00\x00\x00\x00\x00\x00\x00\x8c\x07masonry\x94.'), 'fece555a-32fc-466d-a704-2cc6dc389ce9': pickle.loads(b'\x80\x04K\x03.'), '3826916f-8ec9-4d73-bca3-e88efd913dc9': pickle.loads(b'\x80\x04\x88.'), '41e27623-b662-41ae-a2f0-c19b6a27d1d0': pickle.loads(b'\x80\x04\x95\r\x00\x00\x00\x00\x00\x00\x00\x8c\t#00000000\x94.'), '93fddd13-dc7e-4a2a-aea5-e836ea9d1d63': pickle.loads(b'\x80\x04\x95\x04\x00\x00\x00\x00\x00\x00\x00M\xb0\x04.'), '9b452e55-f09e-4b75-8e29-394099a936ab': pickle.loads(b'\x80\x04\x95\x07\x00\x00\x00\x00\x00\x00\x00\x8c\x03png\x94.'), 'e8c4d7f1-b0e7-4b9c-8df3-d9cbaa715cf6': pickle.loads(b'\x80\x04\x95\x91\x01\x00\x00\x00\x00\x00\x00\x8c%griptape.artifacts.image_url_artifact\x94\x8c\x10ImageUrlArtifact\x94\x93\x94)\x81\x94}\x94(\x8c\x04type\x94\x8c\x10ImageUrlArtifact\x94\x8c\x0bmodule_name\x94\x8c%griptape.artifacts.image_url_artifact\x94\x8c\x02id\x94\x8c be9c66cb570f4cd6987cb2caa7fe8852\x94\x8c\treference\x94N\x8c\x04meta\x94}\x94\x8c\x04name\x94h\n\x8c\x16encoding_error_handler\x94\x8c\x06strict\x94\x8c\x08encoding\x94\x8c\x05utf-8\x94\x8c\x05value\x94\x8cthttp://localhost:8125/workspace/staticfiles/qwen_edit_4_steps_multiple_angles_DisplayImageGrid_grid.png?t=1763638409\x94ub.'), 'ba37688f-f913-4b56-836c-56ab8d668910': pickle.loads(b'\x80\x04\x95\n\x00\x00\x00\x00\x00\x00\x00G@\x10\x00\x00\x00\x00\x00\x00.'), '64f6a8d5-c99f-40b0-b074-64769511715e': pickle.loads(b'\x80\x04\x95\x04\x00\x00\x00\x00\x00\x00\x00M\x00\x04.'), 'e0c9aca1-b0f4-4faf-8a2e-44b970f78bed': pickle.loads(b'\x80\x04K\x04.'), '628f7037-2a46-4a0b-9a2d-7298f2fc4da0': pickle.loads(b'\x80\x04K*.'), 'c460c397-b455-448a-ad86-10ae57a1f05b': pickle.loads(b'\x80\x04\x95\xf9\x00\x00\x00\x00\x00\x00\x00]\x94(\x8c\x17Rotate camera 45\xc2\xb0 left\x94\x8c\x18Rotate camera 45\xc2\xb0 right\x94\x8c\x17Rotate camera 90\xc2\xb0 left\x94\x8c\x18Rotate camera 90\xc2\xb0 right\x94\x8c\x17Switch to top-down view\x94\x8c\x18Switch to low-angle view\x94\x8c\x17Switch to close-up lens\x94\x8c\x1eSwitch to medium close-up lens\x94\x8c\x17Switch to zoom out lens\x94e.'), '2d0c8603-2cd2-4ff2-9244-c7ffd6de74c6': pickle.loads(b'\x80\x04\x95\x1c\x00\x00\x00\x00\x00\x00\x00\x8c\x18Rotate camera 45\xc2\xb0 right\x94.'), '1ab1b979-c306-4d63-b402-655c5cc1df6a': pickle.loads(b'\x80\x04\x95\x1b\x00\x00\x00\x00\x00\x00\x00\x8c\x17Rotate camera 90\xc2\xb0 left\x94.'), 'aaae01c0-c498-4f4c-8f07-2d3ce59bc27a': pickle.loads(b'\x80\x04\x95\x1c\x00\x00\x00\x00\x00\x00\x00\x8c\x18Rotate camera 90\xc2\xb0 right\x94.'), 'e68fcd2c-fc09-4a68-9111-fb3274d38f28': pickle.loads(b'\x80\x04\x95\x1b\x00\x00\x00\x00\x00\x00\x00\x8c\x17Switch to top-down view\x94.'), '2c3d1324-3dec-439a-88fc-24d6810219de': pickle.loads(b'\x80\x04\x95\x1c\x00\x00\x00\x00\x00\x00\x00\x8c\x18Switch to low-angle view\x94.'), '6304c2c0-81f5-4884-9983-f676c952ddae': pickle.loads(b'\x80\x04\x95\x1b\x00\x00\x00\x00\x00\x00\x00\x8c\x17Switch to close-up lens\x94.'), 'cfc0af5c-b723-4f87-9277-c58042795900': pickle.loads(b'\x80\x04\x95"\x00\x00\x00\x00\x00\x00\x00\x8c\x1eSwitch to medium close-up lens\x94.'), '5796655c-6698-4a53-87fb-03703413fdc2': pickle.loads(b'\x80\x04\x95\x1b\x00\x00\x00\x00\x00\x00\x00\x8c\x17Switch to zoom out lens\x94.'), '034b1e45-30b1-4b2f-8465-9802452c908a': pickle.loads(b'\x80\x04\x95\xa1\x05\x00\x00\x00\x00\x00\x00X\x9a\x05\x00\x00# Load LorA - lightx2v/Qwen-Image-Lightning LoRA\n\nThis LoRA is trained to generate images in a fix number of steps with minimal impact to output quality. In our case we are using the 4-step LoRA. The normal recommended number of inference steps for Qwen models is 50, so with 4 steps we get roughly a 12.5x speed up in inference time.\n\nFor more info on the LoRA, see its model page: https://huggingface.co/lightx2v/Qwen-Image-Lightning\n\n## Instructions\n\nWe need to load the LoRA that we downloaded earlier. This is a little unintuitive due to the download location.\n\n1. Click on the folder icon of the file_path parameter in the "Load LoRA" node to the right of this note.\n2. Navigate to to the file path of the required as follows:\n   1. Enable the the "Show hidden files" toggle if not already enabled.\n   2. Click the house icon to jump to the home directory.\n   3. Navigate to `.cache` > `huggingface` > `hub` > **`models--lightx2v--Qwen-Image-Lightning`** > `snapshots` > (the single directory with unreadable name) > **`Qwen-Image-Edit-2509`** \n   4. Select / open the file named **`Qwen-Image-Edit-2509-Lightning-4steps-V1.0-bf16.safetensors`**\n\n> Note that the selected file is a symlink that will get resolved, so after selection you\'ll see the value of `file_path` looks something like `.cache` > `huggingface` > `hub` > `models--lightx2v--Qwen-Image-Lightning` > `blobs` > (a long unreadable string).\n>\n> This is expected.\n\x94.'), '96adb950-aab1-4700-9359-3fa5d44afd54': pickle.loads(b'\x80\x04\x95\x1e\x05\x00\x00\x00\x00\x00\x00X\x17\x05\x00\x00# Load LoRA - dx8152/Qwen-Edit-2509-Multiple-angles\n\nThis LoRA is trained to respect a narrow range of camera controls while mainting scene consistency.\n\nFor more info on the LoRA, see its model page: https://huggingface.co/dx8152/Qwen-Edit-2509-Multiple-angles\n\n## Instructions\n\nWe need to load the LoRA that we downloaded earlier. This is a little unintuitive due to the download location.\n\n1. Click on the folder icon of the file_path parameter in the "Load LoRA" node to the right of this note.\n2. Navigate to to the file path of the required as follows:\n   1. Enable the the "Show hidden files" toggle if not already enabled.\n   2. Click the house icon to jump to the home directory.\n   3. Navigate to `.cache` > `huggingface` > `hub` > **`models--dx8152--Qwen-Edit-2509-Multiple-angles`** > `snapshots` > (the single directory with unreadable name)\n   4. Select the file named **`\xe9\x95\x9c\xe5\xa4\xb4\xe8\xbd\xac\xe6\x8d\xa2.safetensors`** (If you don\'t know chinese, then just look for the single file with the `.safetensors` extension.)\n\n> Note that the selected file is a symlink that will get resolved, so after selection you\'ll see the value of `file_path` looks something like `.cache` > `huggingface` > `hub` > `models--dx8152--Qwen-Edit-2509-Multiple-angles` > `blobs` > (a long unreadable string).\n>\n> This is expected.\n\x94.'), '0ffdef4f-9474-4377-9a49-3ad6863a2b34': pickle.loads(b'\x80\x04\x95\x7f\x04\x00\x00\x00\x00\x00\x00Xx\x04\x00\x00# Diffusion Pipeline Builder\n\n## Notable and Important parameter values\n\n### pipeline_type\n\nThe `QwenImageEditPipeline` (selected) supports 1 input image. If you have a use case for 2 or 3 input images, you can switch to the `QwenImageEditPlusPipeline` and keep the rest of the configuration the same.\n\n### model\n\nThese LoRA technically will work with the `Qwen/Qwen-Image-Edit` and `Qwen/Qwen-Image-Edit-2509` models, but `Qwen/Qwen-Image-Edit` will not obey the camera control prompts as well. In particular it may have trouble keeping the consistency of the scene or distinguishing between "left" and "right" in prompts.\n\n\n### scheduler_config\n\nUsing the lightx2v/Qwen-Image-Lightning LoRA requires a special scheduler configuration as explained on its model page:  https://huggingface.co/lightx2v/Qwen-Image-Lightning\n\nIt\'s already been configured for you here, but note that by default the scheduler_config parameter is hidden on the node. If you ever need to set this property yourself in the future, open the properties sidebar on the right with this node selected and you\'ll be able to hide/show all the parameters available to a node.\n\x94.'), '230065af-269e-4866-b8b5-4eb346376341': pickle.loads(b'\x80\x04\x95\x0e\x04\x00\x00\x00\x00\x00\x00X\x07\x04\x00\x00# Generate Image (Diffusion Pipeline)\n\n## Notable and Important parameter values\n\n### true_cfg_scale\n\nThis must be set to `1` to work with the lightx2v/Qwen-Image-Lightning LoRA. Selecting a value greater than `1` will result in undesirable artifacts in the generated image.\n\n### width and height\n\nFor best results, size of the output image should be roughly equivalent to 1024 x 1024. So different aspect ratios at roughly the same total size should be fine, but drastically smaller or larger images will produce artifacts in the output.\n\n### num_inference_steps\n\nSince we are using the 4-step variant of lightx2v/Qwen-Image-Lightning, this must be exactly 4. Without that LoRA a value of 50 gives best results.\n\n### randomize_seed and seed\n\nYou can get different output images for the same prompt if you modify the seed. Toggling randomize_seed will automatically pick a random seed before each generation. This is useful because occasionally you can still get desired results for a given prompt just by trying a different seed. \x94.'), 'fe68dadc-5fa4-4b4b-af03-c25f65056a67': pickle.loads(b'\x80\x04\x95\x85\x02\x00\x00\x00\x00\x00\x00X~\x02\x00\x00# Prompt List\n\nHere is a list of prompts that are supported by the dx8152/Qwen-Edit-2509-Multiple-angles LoRA.\n\nFor examples of inputs and outputs, see its model page: https://huggingface.co/dx8152/Qwen-Edit-2509-Multiple-angles\n\nThe prompts do not need to have this exact phrasing (they aren\'t "trigger words"), but this is roughly the set of supported camera controls.\n\nYou are of course welcome to experiment, but have the expectation that any camera control prompts that greatly differ from these, or try to modify them may not have the desired effect. For example, this LoRA does not provide the ability to infinitely zoom in or out.\x94.'), 'db86f67f-bb7f-43bb-8328-3e2eb6f8829d': pickle.loads(b'\x80\x04\x95\t\x00\x00\x00\x00\x00\x00\x00\x8c\x05alpha\x94.'), '0445394d-480f-47e3-8205-5aea0391db6c': pickle.loads(b'\x80\x04\x95\x98\x01\x00\x00\x00\x00\x00\x00\x8c%griptape.artifacts.image_url_artifact\x94\x8c\x10ImageUrlArtifact\x94\x93\x94)\x81\x94}\x94(\x8c\x04type\x94\x8c\x10ImageUrlArtifact\x94\x8c\x0bmodule_name\x94\x8c%griptape.artifacts.image_url_artifact\x94\x8c\x02id\x94\x8c dea9a04e734b4e328896764abfe2595a\x94\x8c\treference\x94N\x8c\x04meta\x94}\x94\x8c\x04name\x94h\n\x8c\x16encoding_error_handler\x94\x8c\x06strict\x94\x8c\x08encoding\x94\x8c\x05utf-8\x94\x8c\x05value\x94\x8c{http://localhost:8125/workspace/staticfiles/qwen_edit_2509_camera_control_NOT_TEMPLATE_LoadImage_load_mask.png?t=1763726024\x94ub.'), 'a3ac9cee-93a3-41fa-bf9b-ce87bb3cccf6': pickle.loads(b'\x80\x04\x95\x81\x00\x00\x00\x00\x00\x00\x00\x8c}SUCCESS: Image loaded successfully from image parameter (http://localhost:8125/workspace/staticfiles/chess.webp?t=1763726024)\x94.'), 'c169189b-d3c8-4b47-ad83-199c38eb1174': pickle.loads(b'\x80\x04\x95\x9c\x00\x00\x00\x00\x00\x00\x00\x8c\x98https://raw.githubusercontent.com/griptape-ai/griptape-nodes/refs/heads/main/libraries/griptape_nodes_advanced_media_library/workflows/assets/chess.webp\x94.')}

'# Create the Flow, then do work within it as context.'

flow0_name = GriptapeNodes.handle_request(CreateFlowRequest(parent_flow_name=None, set_as_new_context=False, metadata={})).flow_name

with GriptapeNodes.ContextManager().flow(flow0_name):
    node0_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='DiffusionPipelineBuilderNode', specific_library_name='Griptape Nodes Advanced Media Library', node_name='Diffusion Pipeline Builder', metadata={'position': {'x': 925.5781129246774, 'y': 519.9251048671889}, 'tempId': 'placing-1763551857499-9jlr7l', 'library_node_metadata': NodeMetadata(category='image', description='Build and cache ðŸ¤— Diffusers Pipelines for reuse across multiple execution nodes.', display_name='Diffusion Pipeline Builder', tags=None, icon=None, color=None, group='diffusion', deprecation=None), 'library': 'Griptape Nodes Advanced Media Library', 'node_type': 'DiffusionPipelineBuilderNode', 'showaddparameter': False, 'size': {'width': 604, 'height': 1398}, 'category': 'image'}, initial_setup=True)).node_name
    with GriptapeNodes.ContextManager().node(node0_name):
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='pipeline_type', tooltip='Type of diffusion pipeline to build', type='str', input_types=['str'], output_type='str', ui_options={'simple_dropdown': ['QwenImagePipeline', 'QwenImageImg2ImgPipeline', 'QwenImageEditPipeline', 'QwenImageEditPlusPipeline', 'QwenImageUpscalePipeline'], 'show_search': True, 'search_filter': ''}, mode_allowed_input=False, mode_allowed_property=True, mode_allowed_output=False, is_user_defined=True, settable=True, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='model', default_value='Qwen/Qwen-Image-Edit', tooltip='model', type='str', input_types=['str'], output_type='str', ui_options={'simple_dropdown': ['Qwen/Qwen-Image-Edit', 'Qwen/Qwen-Image-Edit-2509'], 'show_search': True, 'search_filter': '', 'display_name': 'model'}, mode_allowed_input=False, mode_allowed_property=True, mode_allowed_output=False, is_user_defined=True, settable=True, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='text_encoder', default_value='Qwen/Qwen2.5-VL-7B-Instruct', tooltip='text_encoder', type='str', input_types=['str'], output_type='str', ui_options={'simple_dropdown': ['Qwen/Qwen2.5-VL-7B-Instruct'], 'show_search': True, 'search_filter': '', 'display_name': 'text_encoder'}, mode_allowed_input=False, mode_allowed_property=True, mode_allowed_output=False, is_user_defined=True, settable=True, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='scheduler_type', default_value='FlowMatchEulerDiscreteScheduler', tooltip='scheduler_type', type='str', input_types=['str'], output_type='str', ui_options={'simple_dropdown': ['FlowMatchEulerDiscreteScheduler'], 'show_search': True, 'search_filter': '', 'display_name': 'scheduler_type'}, mode_allowed_input=False, mode_allowed_property=True, mode_allowed_output=False, is_user_defined=True, settable=True, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='scheduler_config', tooltip='scheduler_config', type='json', input_types=['json', 'str', 'dict'], output_type='json', ui_options={'display_name': 'scheduler_config', 'show_search': True, 'hide': False}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=False, is_user_defined=True, settable=True, initial_setup=True))
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='attention_slicing', ui_options={'hide': True}, initial_setup=True))
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='vae_slicing', ui_options={'hide': True}, initial_setup=True))
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='transformer_layerwise_casting', ui_options={'hide': True}, initial_setup=True))
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='cpu_offload_strategy', ui_options={'simple_dropdown': ['None', 'Model', 'Sequential'], 'show_search': True, 'search_filter': '', 'hide': True}, initial_setup=True))
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='quantization_mode', ui_options={'simple_dropdown': ['None', 'fp8', 'int8', 'int4'], 'show_search': True, 'search_filter': '', 'hide': True}, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='loras_ParameterListUniqueParamID_f8ebe290a43942598eb9a26c66670d0b', default_value=[], tooltip='loras', type='loras', input_types=['loras', 'dict'], output_type='loras', ui_options={}, mode_allowed_input=True, mode_allowed_property=False, mode_allowed_output=True, is_user_defined=True, settable=True, parent_container_name='loras', initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='loras_ParameterListUniqueParamID_2573cebd2d964cb69dcebea9407a0687', default_value=[], tooltip='loras', type='loras', input_types=['loras', 'dict'], output_type='loras', ui_options={}, mode_allowed_input=True, mode_allowed_property=False, mode_allowed_output=True, is_user_defined=True, settable=True, parent_container_name='loras', initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='loras_ParameterListUniqueParamID_ffd22fd6af524527b759b242e17d7334', default_value=[], tooltip='loras', type='loras', input_types=['loras', 'dict'], output_type='loras', ui_options={}, mode_allowed_input=True, mode_allowed_property=False, mode_allowed_output=True, is_user_defined=True, settable=True, parent_container_name='loras', initial_setup=True))
    node1_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='LoadLora', specific_library_name='Griptape Nodes Advanced Media Library', node_name='Load LoRA', metadata={'position': {'x': -564.3200749333834, 'y': 519.9251048671889}, 'tempId': 'placing-1763554227105-y7f4sf', 'library_node_metadata': NodeMetadata(category='lora', description="Load LoRA from file ('.safetensors', '.pt', '.bin', '.json', '.lora') for use with ðŸ¤— Diffusers based Nodes. Path must be on the engine's filesystem.", display_name='Load LoRA', tags=None, icon=None, color=None, group='diffusion', deprecation=None), 'library': 'Griptape Nodes Advanced Media Library', 'node_type': 'LoadLora', 'showaddparameter': False, 'size': {'width': 600, 'height': 284}, 'category': 'lora'}, initial_setup=True)).node_name
    node2_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='LoadLora', specific_library_name='Griptape Nodes Advanced Media Library', node_name='Load LoRA_1', metadata={'position': {'x': -564.3200749333834, 'y': 1402.32679691464}, 'tempId': 'placing-1763557619770-24w71', 'library_node_metadata': NodeMetadata(category='lora', description="Load LoRA from file ('.safetensors', '.pt', '.bin', '.json', '.lora') for use with ðŸ¤— Diffusers based Nodes. Path must be on the engine's filesystem.", display_name='Load LoRA', tags=None, icon=None, color=None, group='diffusion', deprecation=None), 'library': 'Griptape Nodes Advanced Media Library', 'node_type': 'LoadLora', 'showaddparameter': False, 'size': {'width': 600, 'height': 284}, 'category': 'lora'}, initial_setup=True)).node_name
    node3_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Note', metadata={'position': {'x': -1393.1677077614852, 'y': -707.2145471300643}, 'tempId': 'placing-1763635590779-954ib6', 'library_node_metadata': NodeMetadata(category='misc', description='Create a note node to provide helpful context in your workflow', display_name='Note', tags=None, icon='notepad-text', color=None, group='create', deprecation=None), 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 1045, 'height': 967}, 'category': 'misc'}, initial_setup=True)).node_name
    node4_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='ForEachStartNode', specific_library_name='Griptape Nodes Library', node_name='ForEach Start', metadata={'position': {'x': 3150.8714702935663, 'y': 519.9251048671889}, 'tempId': 'placing-1763635713882-ca7x5f', 'library_node_metadata': NodeMetadata(category='execution_flow', description='Start node for iterating through a list of items and running a flow for each one', display_name='ForEach Start', tags=None, icon='list-start', color=None, group='iteration', deprecation=None), 'library': 'Griptape Nodes Library', 'node_type': 'ForEachStartNode', 'showaddparameter': False, 'size': {'width': 606, 'height': 610}, 'category': 'execution_flow'}, initial_setup=True)).node_name
    node5_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='ForEachEndNode', specific_library_name='Griptape Nodes Library', node_name='ForEach End', metadata={'position': {'x': 5206.3669911930465, 'y': 519.9251048671889}, 'library_node_metadata': NodeMetadata(category='execution_flow', description='End node that completes a loop iteration and connects back to the ForEachStartNode', display_name='ForEach End', tags=None, icon='list-end', color=None, group='iteration', deprecation=None), 'library': 'Griptape Nodes Library', 'node_type': 'ForEachEndNode', 'showaddparameter': False, 'size': {'width': 600, 'height': 372}, 'category': 'execution_flow'}, initial_setup=True)).node_name
    node6_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='DisplayImageGrid', specific_library_name='Griptape Nodes Library', node_name='Display Image Grid', metadata={'position': {'x': 5940.155234368541, 'y': 519.9251048671889}, 'tempId': 'placing-1763635735588-y2lp34', 'library_node_metadata': NodeMetadata(category='image', description='Display multiple images in a grid or masonry layout with customizable styling options', display_name='Display Image Grid', tags=None, icon='grid-3x3', color=None, group='display', deprecation=None), 'library': 'Griptape Nodes Library', 'node_type': 'DisplayImageGrid', 'showaddparameter': False, 'size': {'width': 1194, 'height': 1771}, 'category': 'image'}, initial_setup=True)).node_name
    node7_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='DiffusionPipelineRuntimeNode', specific_library_name='Griptape Nodes Advanced Media Library', node_name='Generate Image (Diffusion Pipeline)', metadata={'library_node_metadata': NodeMetadata(category='image', description='Generate images via ðŸ¤— Diffusers Pipelines.', display_name='Generate Image (Diffusion Pipeline)', tags=None, icon=None, color=None, group='diffusion', deprecation=None), 'library': 'Griptape Nodes Advanced Media Library', 'node_type': 'DiffusionPipelineRuntimeNode', 'position': {'x': 4540.725143788281, 'y': 519.9251048671889}, 'size': {'width': 600, 'height': 1861}, 'showaddparameter': False, 'category': 'image'}, initial_setup=True)).node_name
    with GriptapeNodes.ContextManager().node(node7_name):
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='image', tooltip='Image to be edited.', type='ImageArtifact', input_types=['ImageArtifact', 'ImageUrlArtifact'], output_type='ImageArtifact', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, is_user_defined=True, settable=True, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='prompt', default_value='', tooltip='The prompt or prompts to guide the image editing.', type='str', input_types=['str'], output_type='str', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, is_user_defined=True, settable=True, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='negative_prompt', default_value='', tooltip='The prompt or prompts not to guide the image editing.', type='str', input_types=['str'], output_type='str', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, is_user_defined=True, settable=True, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='true_cfg_scale', default_value=1.0, tooltip='True classifier-free guidance (guidance scale) is enabled when true_cfg_scale > 1 and negative_prompt is provided.', type='float', input_types=['float'], output_type='float', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, is_user_defined=True, settable=True, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='guidance_scale', default_value=4.0, tooltip='Higher guidance_scale encourages a model to generate images more aligned with prompt at the expense of lower image quality.', type='float', input_types=['float'], output_type='float', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, is_user_defined=True, settable=True, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='width', default_value=1024, tooltip='The width in pixels of the generated image.', type='int', input_types=['int'], output_type='int', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, is_user_defined=True, settable=True, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='height', default_value=1024, tooltip='The height in pixels of the generated image.', type='int', input_types=['int'], output_type='int', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, is_user_defined=True, settable=True, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='num_inference_steps', default_value=20, tooltip='The number of denoising steps. More denoising steps usually lead to a higher quality image at the expense of slower inference.', type='int', input_types=['int'], output_type='int', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, is_user_defined=True, settable=True, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='randomize_seed', default_value=False, tooltip='randomize the seed on each run', type='bool', input_types=['bool'], output_type='bool', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, is_user_defined=True, settable=True, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='seed', default_value=42, tooltip='seed', type='int', input_types=['int'], output_type='int', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, is_user_defined=True, settable=True, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='output_image', tooltip='The output image', type='ImageArtifact', input_types=['ImageArtifact'], output_type='ImageArtifact', ui_options={}, mode_allowed_input=False, mode_allowed_property=False, mode_allowed_output=True, is_user_defined=True, settable=True, initial_setup=True))
    node8_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='CreateTextList', specific_library_name='Griptape Nodes Library', node_name='Create Text List_2', metadata={'position': {'x': 2406.5793294336163, 'y': 519.9251048671889}, 'tempId': 'placing-1763635690965-h6pue', 'library_node_metadata': NodeMetadata(category='lists', description='Creates a list of text items', display_name='Create Text List', tags=None, icon=None, color=None, group='create', deprecation=None), 'library': 'Griptape Nodes Library', 'node_type': 'CreateTextList', 'showaddparameter': False, 'size': {'width': 662, 'height': 651}, 'category': 'lists'}, initial_setup=True)).node_name
    with GriptapeNodes.ContextManager().node(node8_name):
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='items_ParameterListUniqueParamID_cdf84aa0dc3642688c2aa39ecaad28eb', tooltip='List of text items to add to', type='str', input_types=['str'], output_type='str', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=False, is_user_defined=True, settable=True, parent_container_name='items', initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='items_ParameterListUniqueParamID_97ef6658379741e7a6d36d759583a25d', tooltip='List of text items to add to', type='str', input_types=['str'], output_type='str', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=False, is_user_defined=True, settable=True, parent_container_name='items', initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='items_ParameterListUniqueParamID_7733d9b6d261418f9df4e52efded5da7', tooltip='List of text items to add to', type='str', input_types=['str'], output_type='str', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=False, is_user_defined=True, settable=True, parent_container_name='items', initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='items_ParameterListUniqueParamID_457d55e1d11f4bb289fd9ec85bbe0496', tooltip='List of text items to add to', type='str', input_types=['str'], output_type='str', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=False, is_user_defined=True, settable=True, parent_container_name='items', initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='items_ParameterListUniqueParamID_b1c7541c08214e58a8f8a48efa977b3d', tooltip='List of text items to add to', type='str', input_types=['str'], output_type='str', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=False, is_user_defined=True, settable=True, parent_container_name='items', initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='items_ParameterListUniqueParamID_0aa469e671cb4f39834b021324a12b14', tooltip='List of text items to add to', type='str', input_types=['str'], output_type='str', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=False, is_user_defined=True, settable=True, parent_container_name='items', initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='items_ParameterListUniqueParamID_1ecd544dc064464d960fdff63f1f49be', tooltip='List of text items to add to', type='str', input_types=['str'], output_type='str', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=False, is_user_defined=True, settable=True, parent_container_name='items', initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='items_ParameterListUniqueParamID_2d927aea9a1a4a12a27b57fbbc35b9ec', tooltip='List of text items to add to', type='str', input_types=['str'], output_type='str', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=False, is_user_defined=True, settable=True, parent_container_name='items', initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='items_ParameterListUniqueParamID_9d0a867506e14ea29544962042fa6f48', tooltip='List of text items to add to', type='str', input_types=['str'], output_type='str', ui_options={}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=False, is_user_defined=True, settable=True, parent_container_name='items', initial_setup=True))
    node9_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Note_1', metadata={'position': {'x': -1393.1677077614852, 'y': 519.9251048671889}, 'tempId': 'placing-1763640602463-ewj1r2', 'library_node_metadata': NodeMetadata(category='misc', description='Create a note node to provide helpful context in your workflow', display_name='Note', tags=None, icon='notepad-text', color=None, group='create', deprecation=None), 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 751, 'height': 729}, 'category': 'misc'}, initial_setup=True)).node_name
    node10_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Note_2', metadata={'position': {'x': -1393.1677077614852, 'y': 1402.32679691464}, 'tempId': 'placing-1763640602463-ewj1r2', 'library_node_metadata': NodeMetadata(category='misc', description='Create a note node to provide helpful context in your workflow', display_name='Note', tags=None, icon='notepad-text', color=None, group='create', deprecation=None), 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 763, 'height': 629}, 'category': 'misc'}, initial_setup=True)).node_name
    node11_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Note_3', metadata={'position': {'x': 92.16118278889553, 'y': 519.9251048671889}, 'tempId': 'placing-1763640602463-ewj1r2', 'library_node_metadata': NodeMetadata(category='misc', description='Create a note node to provide helpful context in your workflow', display_name='Note', tags=None, icon='notepad-text', color=None, group='create', deprecation=None), 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 751, 'height': 704}, 'category': 'misc'}, initial_setup=True)).node_name
    node12_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Note_4', metadata={'position': {'x': 3847.7086178032087, 'y': 519.9251048671889}, 'tempId': 'placing-1763714167719-bzn0ga', 'library_node_metadata': NodeMetadata(category='misc', description='Create a note node to provide helpful context in your workflow', display_name='Note', tags=None, icon='notepad-text', color=None, group='create', deprecation=None), 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 617, 'height': 772}, 'category': 'misc'}, initial_setup=True)).node_name
    node13_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Note_5', metadata={'position': {'x': 1589.8188070901092, 'y': 519.9251048671889}, 'tempId': 'placing-1763715166963-k072or', 'library_node_metadata': NodeMetadata(category='misc', description='Create a note node to provide helpful context in your workflow', display_name='Note', tags=None, icon='notepad-text', color=None, group='create', deprecation=None), 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 731, 'height': 655}, 'category': 'misc'}, initial_setup=True)).node_name
    node14_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='LoadImage', specific_library_name='Griptape Nodes Library', node_name='Load Image', metadata={'position': {'x': 2366.5793294336163, 'y': -786.259480356814}, 'tempId': 'placing-1763725923743-rk011k', 'library_node_metadata': NodeMetadata(category='image', description='Loads an image from disk', display_name='Load Image', tags=None, icon='image-up', color=None, group='Input/Output', deprecation=None), 'library': 'Griptape Nodes Library', 'node_type': 'LoadImage', 'showaddparameter': False, 'size': {'width': 702, 'height': 1008}, 'category': 'image'}, initial_setup=True)).node_name
    with GriptapeNodes.ContextManager().node(node14_name):
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='image', settable=False, initial_setup=True))
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='path', settable=False, initial_setup=True))
    node15_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='TextInput', specific_library_name='Griptape Nodes Library', node_name='Text Input', metadata={'position': {'x': 1655.3188070901092, 'y': -786.259480356814}, 'tempId': 'placing-1763730496605-vn27xl', 'library_node_metadata': NodeMetadata(category='text', description='TextInput node', display_name='Text Input', tags=None, icon='text-cursor', color=None, group='create', deprecation=None), 'library': 'Griptape Nodes Library', 'node_type': 'TextInput', 'showaddparameter': False, 'size': {'width': 600, 'height': 236}, 'category': 'text'}, initial_setup=True)).node_name
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node4_name, source_parameter_name='loop', target_node_name=node5_name, target_parameter_name='from_start', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node4_name, source_parameter_name='loop_end_condition_met_signal', target_node_name=node5_name, target_parameter_name='loop_end_condition_met_signal_input', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node5_name, source_parameter_name='trigger_next_iteration_signal_output', target_node_name=node4_name, target_parameter_name='trigger_next_iteration_signal', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node5_name, source_parameter_name='break_loop_signal_output', target_node_name=node4_name, target_parameter_name='break_loop_signal', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node5_name, source_parameter_name='exec_out', target_node_name=node6_name, target_parameter_name='exec_in', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node5_name, source_parameter_name='results', target_node_name=node6_name, target_parameter_name='images', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node0_name, source_parameter_name='pipeline', target_node_name=node7_name, target_parameter_name='pipeline', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node8_name, source_parameter_name='output', target_node_name=node4_name, target_parameter_name='items', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node15_name, source_parameter_name='text', target_node_name=node14_name, target_parameter_name='image', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node1_name, source_parameter_name='loras', target_node_name=node0_name, target_parameter_name='loras_ParameterListUniqueParamID_f8ebe290a43942598eb9a26c66670d0b', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node2_name, source_parameter_name='loras', target_node_name=node0_name, target_parameter_name='loras_ParameterListUniqueParamID_2573cebd2d964cb69dcebea9407a0687', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node4_name, source_parameter_name='exec_out', target_node_name=node7_name, target_parameter_name='exec_in', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node4_name, source_parameter_name='current_item', target_node_name=node7_name, target_parameter_name='prompt', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node14_name, source_parameter_name='image', target_node_name=node7_name, target_parameter_name='image', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node7_name, source_parameter_name='exec_out', target_node_name=node5_name, target_parameter_name='add_item', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node7_name, source_parameter_name='output_image', target_node_name=node5_name, target_parameter_name='new_item_to_add', initial_setup=True))
    with GriptapeNodes.ContextManager().node(node0_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='pipeline', node_name=node0_name, value=top_level_unique_values_dict['6ed0d013-6611-499f-b6e3-58f072e7c5b9'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='provider', node_name=node0_name, value=top_level_unique_values_dict['67f73190-9d8f-48a9-b621-89959bc6cfff'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='pipeline_type', node_name=node0_name, value=top_level_unique_values_dict['667b485d-c1da-4e48-89a1-553d3a747c57'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='model', node_name=node0_name, value=top_level_unique_values_dict['a1254142-7476-4a5c-8e0a-416d47aa44b9'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='text_encoder', node_name=node0_name, value=top_level_unique_values_dict['966f1035-8051-4146-8dd8-85b1b9d1df37'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='scheduler_type', node_name=node0_name, value=top_level_unique_values_dict['381e4c4b-b524-46c1-bbeb-4bfc7511c73d'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='scheduler_config', node_name=node0_name, value=top_level_unique_values_dict['15bb28e9-4c84-472c-a2d9-17e64ba4d683'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='memory_optimization_strategy', node_name=node0_name, value=top_level_unique_values_dict['bd222443-ac5d-46c8-8973-3f45152ca58f'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='attention_slicing', node_name=node0_name, value=top_level_unique_values_dict['a9ed14cc-8383-4c27-9f75-f42354d5b301'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='vae_slicing', node_name=node0_name, value=top_level_unique_values_dict['a9ed14cc-8383-4c27-9f75-f42354d5b301'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='transformer_layerwise_casting', node_name=node0_name, value=top_level_unique_values_dict['a9ed14cc-8383-4c27-9f75-f42354d5b301'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='cpu_offload_strategy', node_name=node0_name, value=top_level_unique_values_dict['b720d61a-4118-4078-985c-11cd7bdd8672'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='quantization_mode', node_name=node0_name, value=top_level_unique_values_dict['b720d61a-4118-4078-985c-11cd7bdd8672'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='loras', node_name=node0_name, value=top_level_unique_values_dict['c92697b1-f932-47e9-8e49-bf6ad16a1f8c'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='loras_ParameterListUniqueParamID_f8ebe290a43942598eb9a26c66670d0b', node_name=node0_name, value=top_level_unique_values_dict['491f28f3-382c-4153-b570-cde4c0f553e5'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='loras_ParameterListUniqueParamID_2573cebd2d964cb69dcebea9407a0687', node_name=node0_name, value=top_level_unique_values_dict['71564d82-c339-408d-be19-3c4e87cc80d9'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='logs', node_name=node0_name, value=top_level_unique_values_dict['5d1778a1-9003-412a-b0e2-49743433af41'], initial_setup=True, is_output=True))
    with GriptapeNodes.ContextManager().node(node1_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='file_path', node_name=node1_name, value=top_level_unique_values_dict['53d6fb00-893b-47e9-98af-a0240ef6a84b'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='weight', node_name=node1_name, value=top_level_unique_values_dict['06438398-4e7c-47e6-ae57-29d186ea5d9e'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='loras', node_name=node1_name, value=top_level_unique_values_dict['491f28f3-382c-4153-b570-cde4c0f553e5'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='loras', node_name=node1_name, value=top_level_unique_values_dict['491f28f3-382c-4153-b570-cde4c0f553e5'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='trigger_phrase', node_name=node1_name, value=top_level_unique_values_dict['53d6fb00-893b-47e9-98af-a0240ef6a84b'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node2_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='file_path', node_name=node2_name, value=top_level_unique_values_dict['53d6fb00-893b-47e9-98af-a0240ef6a84b'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='weight', node_name=node2_name, value=top_level_unique_values_dict['06438398-4e7c-47e6-ae57-29d186ea5d9e'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='loras', node_name=node2_name, value=top_level_unique_values_dict['71564d82-c339-408d-be19-3c4e87cc80d9'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='loras', node_name=node2_name, value=top_level_unique_values_dict['71564d82-c339-408d-be19-3c4e87cc80d9'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='trigger_phrase', node_name=node2_name, value=top_level_unique_values_dict['53d6fb00-893b-47e9-98af-a0240ef6a84b'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node3_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node3_name, value=top_level_unique_values_dict['81b9fe63-2831-4fbd-bd9d-64f5a46de29d'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node4_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='index', node_name=node4_name, value=top_level_unique_values_dict['12d18190-a9df-4253-9aaf-98661bcdd753'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='index', node_name=node4_name, value=top_level_unique_values_dict['12d18190-a9df-4253-9aaf-98661bcdd753'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='current_item', node_name=node4_name, value=top_level_unique_values_dict['3e2095c3-9066-4a38-a9f5-8f1506b7b84b'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='items', node_name=node4_name, value=top_level_unique_values_dict['16e7f5cc-756a-4782-92f0-046ad6396543'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node5_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='new_item_to_add', node_name=node5_name, value=top_level_unique_values_dict['698c3c68-305c-4ea9-9ec8-6336c3d26233'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='results', node_name=node5_name, value=top_level_unique_values_dict['e4d82818-445a-436f-a6c0-b54d01cdb408'], initial_setup=True, is_output=True))
    with GriptapeNodes.ContextManager().node(node6_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='images', node_name=node6_name, value=top_level_unique_values_dict['dfde1840-9b09-4715-864e-8035334312f9'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='layout_style', node_name=node6_name, value=top_level_unique_values_dict['97e10f91-14e1-489b-a2ff-f2225b9de101'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='columns', node_name=node6_name, value=top_level_unique_values_dict['fece555a-32fc-466d-a704-2cc6dc389ce9'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='spacing', node_name=node6_name, value=top_level_unique_values_dict['12d18190-a9df-4253-9aaf-98661bcdd753'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='border_radius', node_name=node6_name, value=top_level_unique_values_dict['12d18190-a9df-4253-9aaf-98661bcdd753'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='crop_to_fit', node_name=node6_name, value=top_level_unique_values_dict['a9ed14cc-8383-4c27-9f75-f42354d5b301'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='transparent_bg', node_name=node6_name, value=top_level_unique_values_dict['3826916f-8ec9-4d73-bca3-e88efd913dc9'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='background_color', node_name=node6_name, value=top_level_unique_values_dict['41e27623-b662-41ae-a2f0-c19b6a27d1d0'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='output_image_width', node_name=node6_name, value=top_level_unique_values_dict['93fddd13-dc7e-4a2a-aea5-e836ea9d1d63'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='output_format', node_name=node6_name, value=top_level_unique_values_dict['9b452e55-f09e-4b75-8e29-394099a936ab'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='output', node_name=node6_name, value=top_level_unique_values_dict['e8c4d7f1-b0e7-4b9c-8df3-d9cbaa715cf6'], initial_setup=True, is_output=True))
    with GriptapeNodes.ContextManager().node(node7_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='pipeline', node_name=node7_name, value=top_level_unique_values_dict['6ed0d013-6611-499f-b6e3-58f072e7c5b9'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='negative_prompt', node_name=node7_name, value=top_level_unique_values_dict['53d6fb00-893b-47e9-98af-a0240ef6a84b'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='true_cfg_scale', node_name=node7_name, value=top_level_unique_values_dict['06438398-4e7c-47e6-ae57-29d186ea5d9e'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='guidance_scale', node_name=node7_name, value=top_level_unique_values_dict['ba37688f-f913-4b56-836c-56ab8d668910'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='width', node_name=node7_name, value=top_level_unique_values_dict['64f6a8d5-c99f-40b0-b074-64769511715e'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='height', node_name=node7_name, value=top_level_unique_values_dict['64f6a8d5-c99f-40b0-b074-64769511715e'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='num_inference_steps', node_name=node7_name, value=top_level_unique_values_dict['e0c9aca1-b0f4-4faf-8a2e-44b970f78bed'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='randomize_seed', node_name=node7_name, value=top_level_unique_values_dict['a9ed14cc-8383-4c27-9f75-f42354d5b301'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='seed', node_name=node7_name, value=top_level_unique_values_dict['628f7037-2a46-4a0b-9a2d-7298f2fc4da0'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='output_image', node_name=node7_name, value=top_level_unique_values_dict['698c3c68-305c-4ea9-9ec8-6336c3d26233'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node8_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='items', node_name=node8_name, value=top_level_unique_values_dict['c460c397-b455-448a-ad86-10ae57a1f05b'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='items_ParameterListUniqueParamID_cdf84aa0dc3642688c2aa39ecaad28eb', node_name=node8_name, value=top_level_unique_values_dict['3e2095c3-9066-4a38-a9f5-8f1506b7b84b'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='items_ParameterListUniqueParamID_97ef6658379741e7a6d36d759583a25d', node_name=node8_name, value=top_level_unique_values_dict['2d0c8603-2cd2-4ff2-9244-c7ffd6de74c6'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='items_ParameterListUniqueParamID_7733d9b6d261418f9df4e52efded5da7', node_name=node8_name, value=top_level_unique_values_dict['1ab1b979-c306-4d63-b402-655c5cc1df6a'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='items_ParameterListUniqueParamID_457d55e1d11f4bb289fd9ec85bbe0496', node_name=node8_name, value=top_level_unique_values_dict['aaae01c0-c498-4f4c-8f07-2d3ce59bc27a'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='items_ParameterListUniqueParamID_b1c7541c08214e58a8f8a48efa977b3d', node_name=node8_name, value=top_level_unique_values_dict['e68fcd2c-fc09-4a68-9111-fb3274d38f28'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='items_ParameterListUniqueParamID_0aa469e671cb4f39834b021324a12b14', node_name=node8_name, value=top_level_unique_values_dict['2c3d1324-3dec-439a-88fc-24d6810219de'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='items_ParameterListUniqueParamID_1ecd544dc064464d960fdff63f1f49be', node_name=node8_name, value=top_level_unique_values_dict['6304c2c0-81f5-4884-9983-f676c952ddae'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='items_ParameterListUniqueParamID_2d927aea9a1a4a12a27b57fbbc35b9ec', node_name=node8_name, value=top_level_unique_values_dict['cfc0af5c-b723-4f87-9277-c58042795900'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='items_ParameterListUniqueParamID_9d0a867506e14ea29544962042fa6f48', node_name=node8_name, value=top_level_unique_values_dict['5796655c-6698-4a53-87fb-03703413fdc2'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='output', node_name=node8_name, value=top_level_unique_values_dict['16e7f5cc-756a-4782-92f0-046ad6396543'], initial_setup=True, is_output=True))
    with GriptapeNodes.ContextManager().node(node9_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node9_name, value=top_level_unique_values_dict['034b1e45-30b1-4b2f-8465-9802452c908a'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node10_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node10_name, value=top_level_unique_values_dict['96adb950-aab1-4700-9359-3fa5d44afd54'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node11_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node11_name, value=top_level_unique_values_dict['0ffdef4f-9474-4377-9a49-3ad6863a2b34'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node12_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node12_name, value=top_level_unique_values_dict['230065af-269e-4866-b8b5-4eb346376341'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node13_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node13_name, value=top_level_unique_values_dict['fe68dadc-5fa4-4b4b-af03-c25f65056a67'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node14_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='path', node_name=node14_name, value=top_level_unique_values_dict['53d6fb00-893b-47e9-98af-a0240ef6a84b'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='path', node_name=node14_name, value=top_level_unique_values_dict['53d6fb00-893b-47e9-98af-a0240ef6a84b'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='mask_channel', node_name=node14_name, value=top_level_unique_values_dict['db86f67f-bb7f-43bb-8328-3e2eb6f8829d'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='output_mask', node_name=node14_name, value=top_level_unique_values_dict['0445394d-480f-47e3-8205-5aea0391db6c'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='output_mask', node_name=node14_name, value=top_level_unique_values_dict['0445394d-480f-47e3-8205-5aea0391db6c'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='was_successful', node_name=node14_name, value=top_level_unique_values_dict['3826916f-8ec9-4d73-bca3-e88efd913dc9'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='was_successful', node_name=node14_name, value=top_level_unique_values_dict['3826916f-8ec9-4d73-bca3-e88efd913dc9'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='result_details', node_name=node14_name, value=top_level_unique_values_dict['a3ac9cee-93a3-41fa-bf9b-ce87bb3cccf6'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='result_details', node_name=node14_name, value=top_level_unique_values_dict['a3ac9cee-93a3-41fa-bf9b-ce87bb3cccf6'], initial_setup=True, is_output=True))
    with GriptapeNodes.ContextManager().node(node15_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='text', node_name=node15_name, value=top_level_unique_values_dict['c169189b-d3c8-4b47-ad83-199c38eb1174'], initial_setup=True, is_output=False))
